{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def euler_distance(point1: np.ndarray, point2: list) -> float:\n",
    "    \"\"\"\n",
    "    计算两点之间的欧拉距离，支持多维\n",
    "    \"\"\"\n",
    "    distance = 0.0\n",
    "    for a, b in zip(point1, point2):\n",
    "        distance += math.pow(a - b, 2)\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterNode(object):\n",
    "    def __init__(self, vec, left=None, right=None, distance=-1, id=None, count=1):\n",
    "        \"\"\"\n",
    "        :param vec: 保存两个数据聚类后形成新的中心\n",
    "        :param left: 左节点\n",
    "        :param right:  右节点\n",
    "        :param distance: 两个节点的距离\n",
    "        :param id: 用来标记哪些节点是计算过的\n",
    "        :param count: 这个节点的叶子节点个数\n",
    "        \"\"\"\n",
    "        self.vec = vec\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.distance = distance\n",
    "        self.id = id\n",
    "        self.count = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hierarchical(object):\n",
    "    def __init__(self, k = 1):\n",
    "        assert k > 0\n",
    "        self.k = k\n",
    "        self.labels = None\n",
    "    def fit(self, x):\n",
    "        nodes = [ClusterNode(vec=v, id=i) for i,v in enumerate(x)]\n",
    "        distances = {}\n",
    "        point_num, future_num = np.shape(x)  # 特征的维度\n",
    "        self.labels = [ -1 ] * point_num\n",
    "        currentclustid = -1\n",
    "        while len(nodes) > self.k:\n",
    "            min_dist = math.inf\n",
    "            nodes_len = len(nodes)\n",
    "            closest_part = None  # 表示最相似的两个聚类\n",
    "            for i in range(nodes_len - 1):\n",
    "                for j in range(i + 1, nodes_len):\n",
    "                    # 为了不重复计算距离，保存在字典内\n",
    "                    d_key = (nodes[i].id, nodes[j].id)\n",
    "                    if d_key not in distances:\n",
    "                        distances[d_key] = euler_distance(nodes[i].vec, nodes[j].vec)\n",
    "                    d = distances[d_key]\n",
    "                    if d < min_dist:\n",
    "                        min_dist = d\n",
    "                        closest_part = (i, j)\n",
    "            # 合并两个聚类\n",
    "            part1, part2 = closest_part\n",
    "            node1, node2 = nodes[part1], nodes[part2]\n",
    "            new_vec = [ (node1.vec[i] * node1.count + node2.vec[i] * node2.count ) / (node1.count + node2.count)\n",
    "                        for i in range(future_num)]\n",
    "            new_node = ClusterNode(vec=new_vec,\n",
    "                                   left=node1,\n",
    "                                   right=node2,\n",
    "                                   distance=min_dist,\n",
    "                                   id=currentclustid,\n",
    "                                   count=node1.count + node2.count)\n",
    "            currentclustid -= 1\n",
    "            del nodes[part2], nodes[part1]   # 一定要先del索引较大的\n",
    "            nodes.append(new_node)\n",
    "        self.nodes = nodes\n",
    "        self.calc_label()\n",
    "\n",
    "    def calc_label(self):\n",
    "        \"\"\"\n",
    "        调取聚类的结果\n",
    "        \"\"\"\n",
    "        for i, node in enumerate(self.nodes):\n",
    "            # 将节点的所有叶子节点都分类\n",
    "            self.leaf_traversal(node, i)\n",
    "\n",
    "    def leaf_traversal(self, node: ClusterNode, label):\n",
    "        \"\"\"\n",
    "        递归遍历叶子节点\n",
    "        \"\"\"\n",
    "        if node.left == None and node.right == None:\n",
    "            self.labels[node.id] = label\n",
    "        if node.left:\n",
    "            self.leaf_traversal(node.left, label)\n",
    "        if node.right:\n",
    "            self.leaf_traversal(node.right, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 2 1 2 2 2 2 1 2 2 2 2\n",
      " 2 2 1 1 2 2 2 2 1 2 1 2 1 2 2 1 1 2 2 2 2 2 1 2 2 2 2 1 2 2 2 1 2 2 2 1 2\n",
      " 2 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "my = Hierarchical(4)\n",
    "my.fit(iris.data)\n",
    "print(np.array(my.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-95bfe1d30d7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mblognames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data_set/seeds_dataset'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-3c015c8656df>\u001b[0m in \u001b[0;36mread_file\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mline\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#第一行是列标题\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'file' is not defined"
     ]
    }
   ],
   "source": [
    "blognames, words,data = read_file('./data_set/seeds_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "\n",
    "def read_file(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = [line for line in f]\n",
    "        rownames = []\n",
    "        data = []\n",
    "        for line in lines:\n",
    "            p = line.strip().split('\\t')\n",
    "            rownames.append(p[7])\n",
    "            #剩余部分就是该行对应的数据\n",
    "            data.append([ float(x) for x in p[:6]])\n",
    "    return rownames,data\n",
    "\n",
    "\n",
    "\n",
    "def pearson(v1,v2):\n",
    "    #简单求和\n",
    "    sum1 = sum(v1)\n",
    "    sum2 = sum(v2)\n",
    "    \n",
    "    #求平方和\n",
    "    sum1_sq = sum([pow(v,2) for v in v1])\n",
    "    sum2_sq = sum([pow(v,2) for v in v2])\n",
    "    \n",
    "    #求乘积之和\n",
    "    p_sum = sum([v1[i]*v2[i] for i in range(len(v1))])\n",
    "    \n",
    "    #计算r\n",
    "    num = p_sum - (sum1*sum2/len(v1))\n",
    "    den = sqrt((sum1_sq-pow(sum1,2)/len(v1))*(sum2_sq-pow(sum2,2)/len(v1)))\n",
    "    if den == 0:\n",
    "        return 0\n",
    "    return 1.0-num/den\n",
    "\n",
    "def h_cluster(rows,distance=pearson):\n",
    "    distances = {}\n",
    "    current_cluster_id = -1\n",
    "    \n",
    "    #最开始的聚类就是数据集中的行\n",
    "    cluster = [bi_cluster(rows[i],id=i) for i in range(len(rows))]\n",
    "\n",
    "    while(len(cluster)>1):\n",
    "        lowest_pair = (0,1)\n",
    "        closest = distance(cluster[0].vec,cluster[1].vec)\n",
    "        \n",
    "        #遍历每一个配对，寻找最小距离\n",
    "        for i in range(len(cluster)):\n",
    "            for j in range(i+1,len(cluster)):\n",
    "                #用distances来缓存距离的计算值\n",
    "                if(cluster[i].id,cluster[j].id) not in distances:\n",
    "                    distances[(cluster[i].id,cluster[j].id)] = distance(cluster[i].vec,cluster[j].vec)\n",
    "                \n",
    "                d = distances[(cluster[i].id,cluster[j].id)]\n",
    "                \n",
    "                if d<closest:\n",
    "                    closest=d\n",
    "                    lowest_pair=(i,j)\n",
    "        #计算两个聚类的平均值\n",
    "        merge_vec = [(cluster[lowest_pair[0]].vec[i]+cluster[lowest_pair[1]].vec[i])/2.0 for i in range(len(cluster[0].vec))]\n",
    "        \n",
    "        #建立新的聚类\n",
    "        new_cluster = bi_cluster(merge_vec,left=cluster[lowest_pair[0]],right=cluster[lowest_pair[1]],distance=closest,id=current_cluster_id)\n",
    "        \n",
    "        #不在原始集合种的聚类，其id为负数\n",
    "        current_cluster_id-=1\n",
    "        del cluster[lowest_pair[1]]\n",
    "        del cluster[lowest_pair[0]]\n",
    "        cluster.append(new_cluster)\n",
    "        \n",
    "    return cluster[0]\n",
    "\n",
    "def print_cluster(clust,labels=None,n=0):\n",
    "    #利用缩进来建立层级布局\n",
    "    for i in range(n):\n",
    "        print(' ', end='')\n",
    "    if clust.id < 0:\n",
    "        #负数标记代表这是一个分支\n",
    "        print('-')\n",
    "    else:\n",
    "        #正数标记代表这是一个叶节点\n",
    "        if labels == None:\n",
    "            print(clust.id)\n",
    "        else:\n",
    "            print(labels[clust.id])\n",
    "    #现在开始打印右侧分支和左侧分支\n",
    "    if clust.left != None:\n",
    "        print_cluster(clust.left, labels=labels, n=n+1)\n",
    "    if clust.right != None:\n",
    "        print_cluster(clust.right, labels=labels, n= n+1)\n",
    "\n",
    "class bi_cluster:\n",
    "    def __init__(self,vec,left=None,right=None,distance=0.0,id=None):\n",
    "        self.left=left\n",
    "        self.right=right\n",
    "        self.vec=vec\n",
    "        self.id=id\n",
    "        self.distance=distance\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getheight(clusttree):\n",
    "    \"\"\"\n",
    "    绘制树状图--获取聚类数要显示完整需要的高度\n",
    "    :param clusttree:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #若是叶节点则高度为1\n",
    "    if clusttree.left == None and clusttree.left == None:\n",
    "        return 1\n",
    "    #否则，高度为左右分枝的高度之和\n",
    "    return getheight(clusttree.left) + getheight(clusttree.right)\n",
    "\n",
    "\n",
    "def getdepth(clusttree):\n",
    "    \"\"\"\n",
    "    绘制树状图--获取聚类树要显示完整的深度（宽度）\n",
    "    :param clusttree:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #一个叶节点的距离是0.0\n",
    "    if clusttree.left == None and clusttree.right == None:\n",
    "        return 0\n",
    "    #一个叶节点的距离=左右两侧分支中距离较大者+该支点自身的距离\n",
    "    return max(getdepth(clusttree.left), getdepth(\n",
    "        clusttree.right)) + clusttree.distance\n",
    "\n",
    "\n",
    "def drawnode(draw, clust, x, y, scaling, labels):\n",
    "    \"\"\"\n",
    "    画聚类节点以及子聚类节点\n",
    "    :param draw:\n",
    "    :param clust:\n",
    "    :param x:\n",
    "    :param y:\n",
    "    :param scaling:\n",
    "    :param labels:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if clust.id < 0:\n",
    "        h1 = getheight(clust.left) * 20\n",
    "        h2 = getheight(clust.right) * 20\n",
    "        top = y - (h1 + h2) / 2\n",
    "        bottom = y + (h1 + h2) / 2\n",
    "        # 线的长度\n",
    "        ll = clust.distance * scaling\n",
    "        # 聚类到其子节点的垂直线\n",
    "        draw.line((x, top + h1 / 2, x, bottom - h2 / 2), fill=(255, 0, 0))\n",
    "\n",
    "        # 连接左侧节点的水平线\n",
    "        draw.line((x, top + h1 / 2, x + ll, top + h1 / 2), fill=(255, 0, 0))\n",
    "\n",
    "        # 连接右侧节点的水平线\n",
    "        draw.line((x, bottom - h2 / 2, x + ll, bottom - h2 / 2),\n",
    "                  fill=(255, 0, 0))\n",
    "\n",
    "        # 调用函数绘制左右子节点\n",
    "        drawnode(draw, clust.left, x + ll, top + h1 / 2, scaling, labels)\n",
    "        drawnode(draw, clust.right, x + ll, bottom - h2 / 2, scaling, labels)\n",
    "    else:\n",
    "        # 如果这是一个叶节点，则绘制节点的标签文本\n",
    "        draw.text((x + 5, y - 7), labels[clust.id], (0, 0, 0))\n",
    "\n",
    "\n",
    "def drawdendrogram(clusttree, labels, jpeg='clusters.jpg'):\n",
    "    \"\"\"\n",
    "    绘制树状图——为每一个最终生成的聚类创建一个高度为20像素，宽度固定的图片。其中缩放因子是由固定宽度除以总的深度得到的\n",
    "    :param clusttree:\n",
    "    :param labels:\n",
    "    :param jpeg:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 高度和宽度\n",
    "    h = getheight(clusttree) * 20\n",
    "    w = 1200\n",
    "    depth = getdepth(clusttree)\n",
    "\n",
    "    # 由于宽度是固定的，因此我们需要对距离值做相应的调整。（因为显示窗口宽度固定，高度可上下拖动）\n",
    "    scaling = float(w - 150) / depth\n",
    "\n",
    "    # 新建一个白色背景的图片\n",
    "    img = Image.new('RGB', (w, h), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    draw.line((0, h / 2, 10, h / 2), fill=(255, 0, 0))\n",
    "\n",
    "    # 画根节点（会迭代调用画子节点）\n",
    "    drawnode(draw, clusttree, 10, (h / 2), scaling, labels)\n",
    "    img.save(jpeg, 'JPEG')\n",
    "\n",
    "\n",
    "# 数据集转置，进行列聚类。\n",
    "def rotatematrix(data):\n",
    "    newdata = []\n",
    "    for i in range(len(data[0])):\n",
    "        newrow = [data[j][i] for j in range(len(data))]\n",
    "        newdata.append(newrow)\n",
    "    return newdata  #一行表示一个单词在每篇博客中出现的次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "row_names,data = read_file('./data_set/seeds_dataset.txt')\n",
    "clust = h_cluster(data)  #构建层次聚类树\n",
    "#print_cluster(clust,labels=row_names)  # 打印聚类树\n",
    "drawdendrogram(clust, row_names, jpeg='blogclust.jpg')  # 绘制层次聚类树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-21-a88556638c77>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-21-a88556638c77>\"\u001b[1;36m, line \u001b[1;32m17\u001b[0m\n\u001b[1;33m    rownames.append(int(p[7])）\u001b[0m\n\u001b[1;37m                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cluster\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "\"\"\"\n",
    "    产生数据\n",
    "\"\"\"\n",
    "def read_file(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = [line for line in f]\n",
    "        rownames = []\n",
    "        data = []\n",
    "        for line in lines:\n",
    "            p = line.strip().split('\\t')\n",
    "            rownames.append(int(p[7])）\n",
    "            #剩余部分就是该行对应的数据\n",
    "            data.append([ float(x) for x in p[:6])])\n",
    "    return data,rownames\n",
    "\n",
    "def create_data(centers,num=100,std=0.7):\n",
    "    X,labels_true = make_blobs(n_samples=num,centers=centers, cluster_std=std)\n",
    "    return X,labels_true\n",
    "\n",
    "\"\"\"\n",
    "    数据作图\n",
    "\"\"\"\n",
    "def plot_data(*data):\n",
    "    X,labels_true=data\n",
    "    labels=np.unique(labels_true)\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    colors='rgbycm'\n",
    "    for i,label in enumerate(labels):\n",
    "        position=labels_true==label\n",
    "        ax.scatter(X[position,0],X[position,1],label=\"cluster %d\"%label),\n",
    "        color=colors[i%len(colors)]\n",
    "\n",
    "    ax.legend(loc=\"best\",framealpha=0.5)\n",
    "    ax.set_xlabel(\"X[0]\")\n",
    "    ax.set_ylabel(\"Y[1]\")\n",
    "    ax.set_title(\"data\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(<generator object read_file.<locals>.<genexpr> at 0x000001C869ED51B0>,\n",
      "      dtype=object)]\n",
      "['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3', '3']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-930ab561ff66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m \u001b[0mtest_AgglomerativeClustering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[0mplot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[0mtest_AgglomerativeClustering_nclusters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-930ab561ff66>\u001b[0m in \u001b[0;36mtest_AgglomerativeClustering\u001b[1;34m(*data)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mclst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAgglomerativeClustering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mpredicted_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ARI:%s\"\u001b[0m\u001b[1;33m%\u001b[0m \u001b[0madjusted_rand_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\App\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    408\u001b[0m         \u001b[1;31m# non-optimized default implementation; override when a better\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;31m# method is possible for a given clustering algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\App\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\hierarchical.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \"\"\"\n\u001b[1;32m--> 696\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m         \u001b[0mmemory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\App\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"O\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'generator'"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "    测试函数\n",
    "\"\"\"  \n",
    "def test_AgglomerativeClustering(*data):\n",
    "    X,labels_true=data\n",
    "    clst=cluster.AgglomerativeClustering()\n",
    "    predicted_labels=clst.fit_predict(X)\n",
    "    print(\"ARI:%s\"% adjusted_rand_score(labels_true, predicted_labels))\n",
    "\n",
    "\"\"\"\n",
    "    考察簇的数量对于聚类效果的影响\n",
    "\"\"\"\n",
    "def test_AgglomerativeClustering_nclusters(*data):\n",
    "    X,labels_true=data\n",
    "    nums=range(1,50)\n",
    "    ARIS=[]\n",
    "    for num in nums:\n",
    "        clst=cluster.AgglomerativeClustering(n_clusters=num)\n",
    "        predicted_lables=clst.fit_predict(X)\n",
    "        ARIS.append(adjusted_rand_score(labels_true, predicted_lables)) \n",
    "\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    ax.plot(nums,ARIS,marker=\"+\")\n",
    "    ax.set_xlabel(\"n_clusters\")\n",
    "    ax.set_ylabel(\"ARI\")\n",
    "    fig.suptitle(\"AgglomerativeClustering\")\n",
    "    plt.show()   \n",
    "\n",
    "\"\"\"\n",
    "    考察链接方式对聚类结果的影响\n",
    "\"\"\"   \n",
    "def test_agglomerativeClustering_linkage(*data):\n",
    "    X,labels_true=data\n",
    "    nums=range(1,50)\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    linkages=['ward','complete','average']\n",
    "    markers=\"+o*\"\n",
    "    for i,linkage in enumerate(linkages): \n",
    "        ARIs=[]\n",
    "        for num in nums:\n",
    "            clst=cluster.AgglomerativeClustering(n_clusters=num,linkage=linkage)\n",
    "            predicted_labels=clst.fit_predict(X)\n",
    "            ARIs.append(adjusted_rand_score(labels_true, predicted_labels))\n",
    "        ax.plot(nums,ARIs,marker=markers[i],label=\"linkage:%s\"%linkage)\n",
    "\n",
    "    ax.set_xlabel(\"n_clusters\")\n",
    "    ax.set_ylabel(\"ARI\")\n",
    "    ax.legend(loc=\"best\")\n",
    "    fig.suptitle(\"AgglomerativeClustering\")\n",
    "    plt.show()\n",
    "centers=[[1,1],[2,2],[1,2],[10,20]]\n",
    "X,labels_true=read_file('./data_set/seeds_dataset.txt')\n",
    "print(X[0])\n",
    "print(labels_true)\n",
    "test_AgglomerativeClustering(X,labels_true)\n",
    "plot_data(X,labels_true)\n",
    "test_AgglomerativeClustering_nclusters(X,labels_true)\n",
    "test_agglomerativeClustering_linkage(X,labels_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
