{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集数量： 41401\n",
      "测试集数量： 10351\n",
      "训练完成\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import jieba\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "jieba.load_userdict(\"./data_set/userdict.txt\")\n",
    "file_path = './data_set/review.csv'\n",
    "stopword_path = './data_set/stopwords.txt'\n",
    "\n",
    "\n",
    "#加载语料库\n",
    "def load_corpus(corpus_path):\n",
    "    with open(corpus_path, 'r', encoding='UTF-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        rows = [row for row in reader]\n",
    "    review_data = np.array(rows).tolist()\n",
    "    # 打乱数据顺序\n",
    "    random.shuffle(review_data)\n",
    "\n",
    "    review_list = []\n",
    "    sentiment_list = []\n",
    "    for words in review_data:\n",
    "        review_list.append(words[1])\n",
    "        sentiment_list.append(words[0])\n",
    "\n",
    "    return review_list, sentiment_list\n",
    "\n",
    "\n",
    "#加载停用词\n",
    "def load_stopwords(stopword_path):\n",
    "    stop_words = []\n",
    "    with open(stopword_path, encoding='UTF-8') as words:\n",
    "        stop_words.extend([i.strip() for i in words.readlines()])\n",
    "    return stop_words\n",
    "\n",
    "\n",
    "# jieba分词\n",
    "def review_to_text(review):\n",
    "    stop_words = load_stopwords(stopword_path)\n",
    "    review = jieba.cut(review)\n",
    "    all_stop_words = set(stop_words)\n",
    "    # 去掉停用词\n",
    "    review_words = [w for w in review if w not in all_stop_words]\n",
    "\n",
    "    return review_words\n",
    "\n",
    "\n",
    "# 过滤文字中的英文与无关文字\n",
    "def replace_text(text):\n",
    "    text = re.sub(\n",
    "        '((https?|ftp|file)://)?[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|].(com|cn)',\n",
    "        '', text)\n",
    "    text = text.replace('\\u3000', '').replace('\\xa0',\n",
    "                                              '').replace('”',\n",
    "                                                          '').replace('\"', '')\n",
    "    text = text.replace(' ', '').replace('↵', '').replace('\\n', '').replace(\n",
    "        '\\r', '').replace('\\t', '').replace('）', '')\n",
    "    text_corpus = re.split('[！。？；……;]', text)\n",
    "    return text_corpus\n",
    "\n",
    "\n",
    "def cut_word(sentence, stop_words):\n",
    "    words = [i for i in jieba.Tokenizer().cut(sentence) if i not in stop_words]\n",
    "    result = ' '.join(words)\n",
    "    return result\n",
    "\n",
    "\n",
    "# 预测情绪指数\n",
    "def predict_score(text_corpus, tfidftransformer, clf, vectorizer, stop_words):\n",
    "    # 分词\n",
    "    docs = [cut_word(sentence, stop_words) for sentence in text_corpus]\n",
    "    new_tfidf = tfidftransformer.transform(vectorizer.transform(docs))\n",
    "    predicted = clf.predict_proba(new_tfidf)\n",
    "    # 四舍五入，保留三位\n",
    "    result = np.around(predicted, decimals=3)\n",
    "    return result\n",
    "\n",
    "\n",
    "review_list, sentiment_list = load_corpus(file_path)\n",
    "\n",
    "stop_words = load_stopwords(stopword_path)\n",
    "\n",
    "train_review_list, test_review_list, train_sentiment_list, test_sentiment_list = train_test_split(\n",
    "    review_list, sentiment_list, test_size=0.2, random_state=420)\n",
    "\n",
    "print('训练集数量： {}'.format(str(len(train_review_list))))\n",
    "print('测试集数量： {}'.format(str(len(test_review_list))))\n",
    "\n",
    "review_train = [\n",
    "    ' '.join(review_to_text(review)) for review in train_review_list\n",
    "]\n",
    "sentiment_train = train_sentiment_list\n",
    "\n",
    "review_test = [' '.join(review_to_text(review)) for review in test_review_list]\n",
    "sentiment_test = test_sentiment_list\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.8, min_df=3)\n",
    "\n",
    "tfidftransformer = TfidfTransformer()\n",
    "\n",
    "# 先转换成词频矩阵，再计算TFIDF值\n",
    "tfidf = tfidftransformer.fit_transform(vectorizer.fit_transform(review_train))\n",
    "\n",
    "# 朴素贝叶斯中的多项式分类器\n",
    "clf = MultinomialNB().fit(tfidf, sentiment_train)\n",
    "\n",
    "print(\"训练完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集准确率为： 0.798956622548546\n"
     ]
    }
   ],
   "source": [
    "test_tfidf = tfidftransformer.transform(vectorizer.transform(review_test))\n",
    "\n",
    "test_labels = clf.predict(test_tfidf)\n",
    "\n",
    "print ('测试集准确率为： {}'.format(metrics.accuracy_score(test_labels, sentiment_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "交叉验证准确率： 0.7971304021136797\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf,tfidf, sentiment_train,cv=5)\n",
    "\n",
    "print('交叉验证准确率： {}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\二龙熊\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.669 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "差评： 0.217 好评： 0.783\n"
     ]
    }
   ],
   "source": [
    "text = \"如果你不喜欢这部动画电影，那么它不是为你准备的，故事的终章是为真正有童年，不忘初心，老漫迷的人而准备的。\"\n",
    "text_corpus = replace_text(text)\n",
    "result = predict_score(text_corpus, tfidftransformer, clf, vectorizer,\n",
    "                       stop_words)\n",
    "\n",
    "neg = result[0][0]\n",
    "pos = result[0][1]\n",
    "\n",
    "print('差评： {} 好评： {}'.format(neg, pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
